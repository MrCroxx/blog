---
title: "《Web caching with consistent hashing》论文翻译[持续更新中]"
date: 2020-09-10T15:45:45+08:00
lastmod: 2020-09-10T15:45:45+08:00
draft: false
keywords: []
description: ""
tags: ["Consistent Hashing", "Translation"]
categories: ["Paper Reading"]
author: ""
resources:
- name: featured-image
  src: paper-reading.jpg
---

*本篇文章是对论文[Web caching with consistent hashing](http://www.academia.edu/download/49325809/pd1.pdf)的原创翻译，转载请严格遵守[CC BY-NC-SA协议](https://creativecommons.org/licenses/by-nc-sa/4.0/)。*

<!--more-->

## 摘要

对万维网性能测量的关键是内容被提供给用户的速度。随着Web流量的增加，用户面对着日益增加的时延和数据分发故障。Web缓存是已被探索果的用来改进性能的关键策略之一。

许多缓存系统的重要问题是如何在给定时间内决定在哪儿缓存什么数据。解决方案包括组播（multicast）查询和目录策略。

在本文中，我们提供了一个基于*一致性哈希*的新的Web缓存策略。一致性哈希可以替代组播和目录策略，且在负载均衡和容错方面有许多其他优势。一致性哈希的性能在过去的工作中已经通过理论分析过。在本文中，我们描述了一个基于一致性哈希的系统实现和实验。实验支持了一致性哈希能够提供性能改进的论点。

## 1. 引言

随着万维网成为信息分发的主要媒介，能够高效可靠地交付Web流量的机制成为了需求。然而，党建的流量交付方法容易出现不可预测的实验和频繁的故障。这些延时和故障的两个主要原因是网络拥堵和服务器超载。数据在拥堵的网络中传输缓慢。过载的服务器（面对超过其资源所能支持的并发请求）要么会拒接服务，要么会以很慢的速度提供服务。因为网络和服务器的基础设施没有跟上互联网的巨大增长，所以网络拥堵和服务器过载是很常见的。

服务器和网络可能在没有任何事先通知的情况下过载。例如，在晚间新闻中被称为“当天的酷网站”的站点，可能不得不处理第二天增长了一万倍的流量。因此，提前计划能带来的好处很有限，处理负载的最佳策略是适应不断变化的环境。

### 1.1 Web缓存

缓存被用作提高Internet的数据交付性能和可靠性。即使在原始服务器已经过载或到该服务器的网络拥堵的情况下，附近的缓存仍可以快速地为（缓存中的）页面提供服务。这一好处给仅关心自己的服务的用户带来的利用缓存的理由，且如果缓存能被广泛应用，那么还会带来另一个好处：如果请求能够被附近的缓存截获，那么去往源服务器的流量就会减少，减少服务器上的网络流量会为所有用户带来好处。

通过一台单独的共享缓存的机器为一组用户提供服务的这种最简单的做法有很多缺点。如果缓存机器故障，那么所有用户都不能连接Web。即使缓存机器正常运行，单台缓存机器能提供服务的用户数还是受限，且在一段高强度的使用后可能成为瓶颈。最后，单个缓存可以达到的命中率主要受两个因素限制。第一，因为可用的存储总量有限，当请求重复访问因缺少空间而被驱逐的对象时，会造成“假失配（false misses）”现象。第二，缓存能提供服务的用户数的限制与缓存想尽可能地聚合用户请求的目的相驳：通常，被聚合到一起的用户请求越多，每个用户请求已被其他用户请求过的对象时命中率就会越高。

### 1.2 相关工作

为了达到容错、可伸缩并聚合大量请求（以提高命中率），一些团队<sup>[2, 4, 5, 7]</sup>提出了一些使用*协作式缓存（copperating caches）*的系统。这些系统都共享了确定的通用数据。每个client选取系统中的一个主（primary）缓存。来自该client的请求会通往主缓存。如果主缓存失配，请求会试图在其他协作缓存中定位被请求的资源，而不是直接访问内容服务器。如果成功，资源将会从（可能更近的）协作缓存中，而不是从较慢的内容服务器中取出。因此，其他协作缓存被用作“二级缓存”来减少主缓存的失配开销。

这两种系统的区别在于，当主缓存失配时的数据定位方式。一下策略会使用组播<sup>[7]</sup>或UDP广播<sup>[2]</sup>将请求广播到其他缓存中。这样做，除了查询的广播消耗了额外的带宽外，如果数据失配，主缓存在联系内容服务器之前必须等待所有协作缓存报告其适配，这会降低二级缓存失配时的性能。其他的策略使用了目录，这些策略或者是集中式的<sup>[5]</sup>或者需要反复广播以支持本地查询<sup>[4]</sup>。目录的查询或传输还是需要消耗带宽，且集中式的目录会成为新的系统故障点<sup>[5]</sup>。

这些系统的另一个问题是缓存中的数据冗余。任何一个缓存都可能收到对任一份数据的查询，这会导致缓存中保存了一份副本。在二级缓存命中时，网络带宽和时间被浪费在了将数据拷贝到另一个缓存上。更糟糕的是，这些拷贝会驱逐被请求的其他网页，这样削减了缓存命中数。如果协作缓存都“靠近”彼此，用户可能希望通过将每个对象仅保存在一个或少数几个机器上来得到一个（假失配更少的）更大的缓存<sup>[9]</sup>。

### 1.3 我们的工作

本文中，我们提出了一种消除了所有缓存间通信，但允许整个系统中的缓存表现得像一整个缓存一样的方法。Cache Resolver是我们开发的分布式Web缓存系统，其通过让client自己决定从哪个缓存请求数据的方式，消除了失配时缓存建的通信。在失配时，用户的浏览器（客户端）会直接联系应该包含被请求的资源的缓存，而不是联系主缓存来定位被请求的数据应该在其他哪个缓存=上。浏览器通过一个能将资源（或URL）映射到一个动态变化的可用缓存的集合的哈希函数，来做出决定。

哈希方法比广播和基于目录的策略提供了几个好处。一台机器可以在本地计算哪个缓存应该包含给定的对象。使用单播就足以获得对象或确定它没被缓存，这与其他方案相比较少了网络使用。它还能够比需要等待所有缓存响应的组播策略更快地发现失配。它与基于目录的策略相比，减少了维护和查询的额外开销。它还不会使系统产生新的故障点。事实上，我们的策略展示了很强的可靠性，我们将在后文中讨论。

虽然以上的好处就似乎已经足以让让用户选择基于哈希的解决方案，但我们还是探索了另一个方面：它让我们将页面（资源）定位任务推给了独立的client端。基于哈希的策略可以很容易地在浏览器级别下实现，而基于目录的定位策略因开销过大而不能在每个浏览器中实现。因此，过去的策略会假设每个client总是联系一个固定的主缓存，当主缓存失配时，它会联系其它缓存来看它们是否有请求的页面（资源）。而我们让浏览器直接决定联系哪个缓存。这移除了对中间缓存的需要，以改进响应时间。另外，因为所有client在访问同一个给定的页面的时候会联系相同的缓存，因此，无论有多少个一起协作的缓存，我们的缓存系统在查询每个页面时只会经历一次失配，而不是每个页面会在每个缓存中都会（在主缓存中）失配一次。因为我们避免页面的冗余副本，为其他页面留出了更多在缓存中的空间，所以我们可以进一步减小失配率。

虽然基于哈希的策略有很多吸引人的属性，但是为了正确地实现它，必须考虑一些重要的问题。一篇理论方面的论文建立了一个被称为*一致性哈希*的工具来解决这些问题中的一些<sup>[6]</sup>。这是我们当前实现的工作的基础。

在Internet草案<sup>[3]</sup>中，也出现了相似的*缓存数组路由协议（Cache Arrayh Routing Protocal，CARP）*提议。Microsoft Proxu Cache<sup>[8]</sup>中使用了CARP。CARP从直觉上与我们的方法有很多相同之处，尽管它还没被从理论上证明。我们的提议与CARP的重要的不同之处在于我们的哈希算法是如何实现的。目前的浏览器不具备支持CARP这样额方案的所有功能。CARP将所有一致性哈希的的责任交给了浏览器，这样会有很多缺点，我们会在后文中讨论。相反，我们通过不寻常（但是正确）的方式使用DNS来为浏览器对哈希函数的使用提供支持。通过对浏览器进行修改，一致性哈希可以完全在浏览器中实现，无需依赖DNS。然而，从长远看来，通过DNS方法提供的一些好处可能会使其成为正确的选择。

### 1.4 论文概览

在本文的[第二章](#2-)中，我们详细地描述了一致性哈希。在[第三章](#3-)中，我们描述了我们使用一致性哈希算法的Web缓存系统的实现，我们将我们的系统与其他Web缓存系统在[第四章](#4-)中进行了比较。在[第五章](#5-)中，我们提到了我们的缓存系统在其他方面的好处，如容错和负载均衡。在[第六章](#6-)中我们进行了总结。

## 2. 一致性哈希

我们的系统基于一致性哈希，它是一篇以前的理论性的论文创建的策略<sup>[6]</sup>。这里，我们将介绍一致性哈希并描述其简单的实现方式。在概述其理论证明后，我们通过实验展示了在实际场景中它工作得很好。

### 2.1 需求

我们的系统的目标是让任何一个client都能通过本地计算来将URL映射到包含它的缓存上。哈希是为实现这一目的被广泛使用的工具。例如，给定一个编号为0，...，22的缓存的23个缓存的集合，我们可能使用$h[u]=7u+4mod23$来将URL $u$映射到缓存$h$（我们可以将URL看做表示一个大数字的位字符串）。通常，根据对哈希函数的直觉，其倾向于把输入“随机地”分配的可能的位置上。这样的随机分布直观上看是均匀的，这意味着没有一个缓存负责处理不成比例的请求页面。哈希的这种负载均衡的特性是我们的应用程序高度需要的特性，因为负载不成比例的缓存将会成为整个系统的瓶颈。

不幸的是，标准的哈希在缓存系统中应用时会有一些缺点。或许最明显的缺点是，系统中的缓存机器数可能会随着时间上下波动。试想一下，当第24个缓存加入到刚才描述的系统中时会发生什么。一个很自然的变化是开始使用哈希函数$h'(u)=7u+4mod24$。不幸的是，在这种改变下，原本的每个URL会被映射到新的缓存上。这会使整个缓存系统中的URL都被刷新：如果系统查找一个在新位置上的URL，那么事实上它在旧位置上的缓存就没用了，会产生一次失配。信息通过Internet异步传播的这一事实会加剧这一问题。在任何一个时刻，不同的client对哪些缓存在线哪些缓存离线都有不同的信息。我们将一台给定的机器所知道的缓存集合成为它的*视图（view）*，我们观察到，在任何时刻，系统中都有很多不同的视图。这样会有两个潜在的缺点。