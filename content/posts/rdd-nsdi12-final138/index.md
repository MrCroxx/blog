---
title: "《Resilient Distributed Datasets: A Fault-Tolerant Abstraction for In-Memory Cluster Computing》论文翻译（RDD-NSDI12-FINAL138）"
date: 2020-09-07T11:14:45+08:00
lastmod: 22020-09-07T11:14:45+08:00
draft: false
keywords: []
description: ""
tags: ["RDD", "Translation"]
categories: ["Paper Reading"]
author: ""
resources:
- name: featured-image
  src: paper-reading.jpg
---

*本篇文章是对论文[RDD-NSDI12-FINAL138](https://www.usenix.org/system/files/conference/nsdi12/nsdi12-final138.pdf)的原创翻译，转载请严格遵守[CC BY-NC-SA协议](https://creativecommons.org/licenses/by-nc-sa/4.0/)。*


<sup>[]</sup>

<!--more-->

## 摘要

我们提出了一个能够使开发者在大型集群上执行内存式计算且带有容错的分布式内存的抽象——Resilient Distributed Datasets（RDDs，弹性分布式数据集）。RDDs的想法由在当前计算框架中处理效率不高的两类应用程序驱动：迭代算法和交互式数据挖掘工具。在这两种情况下，将数据保存在内存中能够将性能提高一个数量级。为了实现有效地容错，RDDs提供了共享内存的一个受限的形式，其基于粗粒度的变换而不是细粒度的共享状态更新。然而，我们发现RDDs足以表示很广泛的计算类型，包括最近像Pregel一样的专门针对迭代任务的程序模型，以及在新应用程序中这些模型表达不出的模型。我们在被称为Spark的系统中实现了RDDs，并通过各种用户程序和benchmark来评估这个系统。

## 1. 引言

像MapReduce<sup>[10]</sup>和Dryad<sup>[19]</sup>之类的集群计算框架已广泛引用于大规模数据分析。这些系统让用户可以通过一系列高层操作来编写并行计算，不需要担心工作的分布与容错。

尽管当前的框架提供了大量访问集群资源的抽象，它们仍缺少对利用分布式内存的抽象。这使它们对一类新兴的重要应用程序来说效率很低。这类新兴的应用程序会复用（reuse）多个计算的中间结果。数据复用在很多迭代（iterative）式机器学习和图算法（包括PageRank、K-means聚类、逻辑回归等）中很常见。另一个备受关注的使用场景是交互式数据挖掘，该场景下用户会在同一个数据的子集上运行多个临时查询。不幸的是，在大部分当前的框架中，在计算间（如两个MapReduce的job间）复用数据的唯一方式是将其写入外部稳定存储系统，如分布式文件系统。由于这样做需要数据副本、磁盘I/O和序列化等占用大部分程序执行时间的操作，这会导致非常可观的额外开销。

由于意识到了这一问题，研究者们已经开发了为一些需要复用数据的应用程序专门设计的框架。例如，Pregel<sup>[22]</sup>是一个为迭代式图计算设计的系统，其能将中间数据保存在内存中；HaLoop<sup>[7]</sup>提供了迭代式MapReduce接口。然而，这些框架仅支持特殊的编程模式（例如，循环一系列MapReduce的step），并在这些模式中进行隐式数据共享。它们不支持更普遍的数据复用抽象，如允许用户将几个数据集加载到内存中并运行跨这些数据集的临时查询。

在本文中，我们提出了一种新的抽象——resilient distributed datasets（RDDs），其能在广泛的应用程序中进行高效数据复用。RDDs是能容错的并行数据结构，其使用户能够显式地将中间结果在内存中持久化，并控制它们的分区以优化数据放置，且能够对其使用丰富的操作。

设计RDDs的主要挑战是定义能够高效地提供容错的编程接口。已有的为集群中内存式存储（分布式共享内存<sup>[24]</sup>、键值存储<sup>[25]</sup>数据库和Piccolo<sup>[27]</sup>等）设计的抽象，提供了基于细粒度更新（fine-grained update）变更状态（如表中的单元格）的接口。在这种接口中，提供容错的唯一几种方式是将数据跨机器做副本或跨机器记录更新日志。这两种方法对于数据敏感性工作负载来说开销过于高昂，因为它们需要通过集群的网络复制大量的数据，而集群的网络带宽远低于RAM，且它们造成了大量的存储额外开销。

与这些系统不同，RDDs提供了基于粗粒度（coarse-grained）的变换（如map、filter和join）接口，其对许多数据项应用相同的操作。这使它们能够通过记录构建数据集（和数据集的延伸）使用的变换而不是对实际数据使用的变换的方式，来高效地提供容错<sup>[注1]</sup>。如果RDD的一个分区丢失，RDD有足够的关于它如何被从其它RDDs导出的信息，来重新计算仅这一分区。因此，丢失的数据可被恢复，数据恢复速度通常非常快，且不需要开销高昂的副本。

> 注1：在一些RDDs中，当数据的延伸链增长得很大时，对数据建立检查点非常有用。我们将在[章节5.4](#54-)中讨论如何操作。

尽管基于粗粒度变换的接口最初似乎非常有限，但RDDs仍非常适用于许多并行程序，因为这些程序本身就对许多数据项应用相同的操作。事实上，我们发现RDDs可以高效地表示很多集群编程模型，目前这些模型被不同的系统分别提出，其包括MapReduce、DryadLINQ、SQL、Pregel和HaLoop，以及新式应用程序中无法表示的模型，如交互式数据挖掘。RDDs的这种仅通过引入新的框架就能适配过去已经满足了的计算需求的能力，在我们看来是RDD抽象能力最令人信服的证据。

我们在被称为Spark的系统中实现了RDDs，该系统被在UC Berkeley和许多公司的研究和生产应用程序中使用。Spark在Scala编程语言<sup>[2]</sup>中提供了一个类似DryadLINQ<sup>[31]</sup>的很方便的集成语言编程接口（language-integrated programming interface）。另外，Spark可被在Scala解释器中交互式查询大数据集时使用。我们认为Spark是第一个能够以交互所需的速度使用通用编程语言在集群中进行内存数据挖掘的系统。

我们通过小批量benchmark和在我们的应用程序中测量的方式来评估RDDs和Spark的性能。我们发现Spark在迭代式应用程序中比Hadoop快了20倍，在真实的数据分析报告中快了40倍，且可在交互时以5~7秒的延时来扫描1TB的数据集。