---
title: "《XORing Elephants: Novel Erasure Codes for Big Data》论文翻译（arXiv:1301.3791v1）"
date: 2020-09-03T12:01:45+08:00
lastmod: 2020-09-03T12:01:45+08:00
draft: false
keywords: []
description: ""
tags: ["Erasure Code", "Translation"]
categories: ["Paper Reading"]
author: ""
resources:
- name: featured-image
  src: paper-reading.jpg
---

*本篇文章是对论文[XORing Elephants: Novel Erasure Codes for Big Data](https://arxiv.org/pdf/1301.3791.pdf)的原创翻译，转载请严格遵守[CC BY-NC-SA协议](https://creativecommons.org/licenses/by-nc-sa/4.0/)。*


<!--more-->

## 摘要

大型分布式存储系统通常使用副本来提供可靠性。最近，为了减少三副本系统带来的巨大开销，开始使用纠删码。在设计时，一般选择Reed-Solomon码（RS码）作为标准，其高昂的修复开销往往被认为是为了高效存储和高可用性而带来的不可避免的代价。

本篇论文展示了如何克服这一限制。我们提出了一个新的擦除码族，它们可以高效修复并提供比RS码更高的可靠性。我们通过分析表明，我们的编码在权衡局部性和最短距离时能做出最优的决策。我们在Hadoop HDFS中实现了我们的新的编码方式，并与当前部署的使用了RS码的HDFS模块做了比较。我们修改的HDFS实现在修复时减少了约2倍的磁盘I/O和网络流量。新的编码方案的缺点是在修复时需要修复比RS码多出14%的存储，这是从信息论角度为了获得部性最优的开销。因为我们新的编码方案能够更快地修复故障，因此其能够提供比副本的方式高几个数量级的可靠性。

## 1. 引言

MapReduce架构因其高伸缩性而在大数据管理中心变得越来越流行。在Facebook中，大型分析集群存储了PB级信息并使用Hadoop MapReduce处理很多的分析任务。其标准实现依赖一个通过利用了三副本的块来提供可靠性的分布式文件系统。副本策略的主要缺点在于其需要高达200%的额外存储开销，这一开销会反映在集群的开销上。当管理的数据快速增长时，这一开销会取代数据中心基础设施成为主要的瓶颈。

因此，Facebook和许多其他厂商正在切换到纠删码技术（通常指RS码）来在节约存储的同时引入冗余，特别对于那些更像是归档的数据。在本文中，我们展示了传统的编码在分布式的MapReduce架构中离最优有很大差距。我们介绍了新的编码方式，以解决分布式系统可靠性和信息论约束的主要挑战，这也显示了我们的结构是最优的。本文依赖于对一个使用了Hadoop MapReduce来做数据分析的大型Facebook生产集群（超过3000个结点、30PB的逻辑数据存储）的测量。Facebook最近开始部署一个依赖RS码的叫做HDFS RAID的开源HDFS模块。在HDFS RAID中，“cold（即很少被访问的）”文件的副本因子被降为1，并为其创建一个包含奇偶block的新的奇偶文件。

Facebook集群中使用的参数为，每个大文件的数据block被分组为10个stripe，并对每个stripe创建了4个奇偶校验block。太系统（被称为RS）可以容错任意4个block的故障，且其额外开销仅为40%。因此，RS码能提供比副本更强的健壮性和存储性能。事实上，该方案存储的额外开销对于该级别的可靠性来说是最小的。实现了这种最佳的存储和可靠性折中的编码被称作是Maximum Distance Separable（MDS）的，RS码就是MDS族中被最广泛使用的编码方式。

传统的纠删码在分布式环境中不是最优的，这时由于修复问题（Repair problem）：当一个节点故障时，通常每个stripe中被存储在该节点上的一个block会丢失。即使仅有一个block丢失，RS码通常会使用需要传输10个block并重建这10个原始的block的数据的方式的简单方案来修复，这导致了在修复时产生了10倍的对带宽和磁盘I/O的额外负载。

最近，信息论的研究结果表明，和这种朴素方式相比，能够使用更少的网络带宽来修复纠错码。最近已经有大量关于设计这种高效的可修复的编码的工作，在[第六章](#6-)中有对这些文献的概览。

**我们的贡献：**