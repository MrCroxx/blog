---
title: "《In Search of an Understandable Consensus Algorithm (Extended Version)》论文翻译 [持续更新中]"
date: 2020-09-27T19:26:30+08:00
lastmod: 2020-09-27T19:26:34+08:00
draft: false
keywords: []
description: ""
tags: ["Raft", "Translation"]
categories: ["Paper Reading"]
author: ""
resources:
- name: featured-image
  src: paper-reading.jpg
---

*本篇文章是对论文[In Search of an Understandable Consensus Algorithm (Extended Version)](http://pages.cs.wisc.edu/~remzi/Classes/739/Spring2004/Papers/raft.pdf)的原创翻译，转载请严格遵守[CC BY-NC-SA协议](https://creativecommons.org/licenses/by-nc-sa/4.0/)。*


<!--more-->

## 摘要

Raft是一个用来管理多副本日志（replicated log）的共识算法。其作用与（multi-）Paxos相同、效率与Paxos想用，但结构与Paxos不同；这让Raft比Paxos更容易理解，且Raft为构建实用的系统提供了更扎实的基础。为了提高可理解性，Raft将共识的关键元素分离为：领导选举、日志复制、和安全性；且其增强了连贯性（coherency）<sup>译注1</sup>，以减少必须考虑的状态数。用户学习结果表明，对于学生来说，Raft比Paxos更容易学习。Raft还包括一个用于变更集群成员的新机制，其使用重叠的大多数来保证安全性。

> 译注1：本文的连贯性指*coherency*，在很多翻译中将其翻译成了一致性，这样容易与*consistency*混淆，二者间存在一定差异。

## 1. 引言

共识算法让一组机器能像能容忍一些成员故障的一个连贯组一样工作。因为这一点，它们在构建可靠的大规模软件系统中扮演者关键角色。Paxos<sup>[15, 16]</sup>在过去的十年中主导了共识算法的讨论：大多数共识的实现都基于Paxos或受其影响，且Paxos成为了用来教授学生有关共识知识的主要工具。

不幸的是，Paxos相当难以理解，尽管有很多使其更易接受的尝试。另外，其架构需要复杂的修改以支持实用的系统。其结果是，系统构建者和学生都很受Paxos困扰。

在我们自己饱受Paxos困扰后，我们开始寻找一个能够为系统构建和教育提供更好的基础的新的共识算法。我们的方法不太寻常，因为我们的主要目标是*可理解性*：我们能否定义一个为实用系统设计的共识算法，并用一个比Paxos更容易学习的方式描述它？此外，我们希望算法能够让开发更加直观，这对系统构建者来说是很重要的。重要的不光是算法，还有为什么算法能工作。

这项工作的成果是一个被称为**Raft**的共识算法。在设计Raft时，我们使用了特殊的方法来提高可理解性，包括算法分解（Raft将领导选举、日志复制、和安全性分离开来）和减少状态空间（与Paxos相比，Raft减少了不确定性，且该方法允许服务器相互不一致）。对两个大学的43个学生的研究表明，Raft比Paxos更好理解得多：在学习这两种算法后，这些学生中的33名能够更好得回答有关Raft的问题。

Raft与现有的共识算法在很多方面都很相似（最明显的时候，Oki和Liskov的Viewstamped Replication<sup>[29, 22]</sup>），但Raft有很多新特性：

- **强leader：** 与其它共识算法相比，Raft使用了更强的领导权形式。例如，日志条目(log entry)仅从leader流向其它服务器。这简化了对多副本日志的管理，并使Raft更容易理解。

- **领导选举：** Raft使用随机计时器来选举leader。这仅在任何共识算法都需要的心跳机制上增加了很小的机制，但能够简单又快速地解决冲突。

- **成员变更：** Raft用来变更集群中服务器集合的机制使用了一个新的*联合共识（joint consensus）*方法，其两个不同配置中的大多数服务器会在变换间有重叠。这让集群能够在配置变更时正常地继续操作。

我们认为，无论为了教育目的还是作为实现的基础，Raft都比Paxos和其它共识算法更优秀；Raft的描述足够完整，能够满足使用系统的需求；Raft有很多开源实现并已经被一些公司使用；Raft的安全性性质已经被形式化定义并证明；Raft的效率与其它算法相似。

本文的剩余部分介绍了多副本状态机问题（[第二章](#2-)），讨论了Paxos的优势与劣势（[第三章](#3-)），描述了我们为了可理解性使用的通用方法（[第四章](#4-)），给出了Raft共识算法（[第5~8章](#5-)），评估了Raft（[第九章](#9-)），并讨论了相关工作（[第十章](#10-)）。

## 2. 多副本状态机

共识算法通常在*多副本状态机问题（replicated state machine problem）*<sup>[37]</sup>的上下文中出现。通过这种方法，在一系列服务器上的状态机会计算相同状态的相同副本，且即使在一些服务器宕机是也可以继续操作。多副本状态机被用来解决分布式系统中各式各样的容错问题。例如，有单集群leader的大型系统（如GFS<sup>[8]</sup>、HDFS<sup>[38]</sup>、和RAMCloud<sup>[33]</sup>）通常使用独立的多副本状态机来管理领导选举并存储必须能在leader崩溃时幸存的配置信息。多副本状态机的例子还包括Chubby<sup>[2]</sup>和ZooKeeper<sup>[11]</sup>。

多副本状态机通常使用多副本日志实现，如**图1**所示。每个服务器存储一个包含一系列指令的日志，状态机会按照顺序执行日志。每个日志包含相同顺序的相同指令，因此每个状态机会处理相同的指令序列。因为状态机是确定的，每个状态机都会计算出相同的状态并得出相同的输出序列。

![图1 多副本状态机架构。共识算法管理由来自不同客户端的状态及指令组成的多副本日志。状态机按照日志处理相同的指令序列，因此它们会产生相同的输出。](figure-1.png "图1 多副本状态机架构。共识算法管理由来自不同客户端的状态及指令组成的多副本日志。状态机按照日志处理相同的指令序列，因此它们会产生相同的输出。")

保持多副本日志的一致性是共识算法的任务。服务器上的共识模块会接收来自客户端的指令，并将其添加到它的日志中。它与其它服务器上的共识模块通信来确保每个日志最终包含相同顺序的相同请求，即使一些服务器故障也是如此。一旦指令被恰当地多副本化，每个服务器的状态机就可以按日志顺序处理它们，并将输出返回给客户端。这样，所有服务器对外会表现为单个高可靠性的状态机。

为实用系统设计的共识算法通常有如下属性：

- 它们确保所有非拜占庭条件下的安全性（永远不会返回错误结果），需要处理的问题包括网络延迟、分区、丢包、重复、和乱序。

- 只要大多数服务器可以操作那么其所有功能都可用，且能够与相遇通信或与客户端通信。因此，通常使用的由5个服务器组成的集群能够容忍任意2个服务器故障。服务器被假设可能宕机停止；它们也可能在随后从稳定存储中恢复并重新加入集群。

- 它们不依赖定时来保证日志的一致性：在最坏的情况下，时钟故障和极端的消息延迟会导致可用性问题。

- 在通常情况下，一条指令能在集群的大多数响应一轮远程过程调用（RPC）后完成；少数的较慢的服务器不会影响整个系统的性能。

## 3. Paxos有什么问题？

在过去十年中，Leslie Lamport的Paxos协议<sup>[15]</sup>几乎和共识成了同义词：Paxos是在课程中最常被教授的协议，也是大多数共识实现的起点。Poxos首先定义了一个能够对单个决策达成一致的协议，如单个多副本日志条目。我们称这个子集为*单决策Paxos（single-decree Paxos）*。Paxos接着将该协议的多个实例结合，以实现一系列的决策，例如一个日志（multi-Paxos）。Paxos同时确保了安全性和活性（liveness），且它支持集群中成员的变更。它的正确性已经被证明，且Paxos在一般场景下很高效。

不幸的是，Paxos有两个显著的劣势。第一个劣势是Paxos非常难以理解。众所周知，Paxos的完整解释<sup>[15]</sup>非常隐晦；只有很少的人在付出很大努力后才能成功理解它。因此，出现了很多试图通过更简单的方式解释Paxos的尝试<sup>[16, 20, 21]</sup>。这些解释着手于单决策Paxos这一子集，尽管这仍很有挑战。在对NSDI2012出席者的非正式调查中，我们发现尽管在经验丰富的研究者中，也几乎没有人觉得Paxos容易。我们自己就受Paxos困扰，直到阅读了一些简化的解释后我们才理解了完整的协议，所以我们设计了自己的替代的协议，这一过程花了差不多一年时间。

我们假设Paxos的隐晦性来自于其选择了单决策子集作为其基础。单决策Paxos很冗杂且隐晦：单决策Paxos被分为两个阶段，其没有简单的直观解释也不能被单独理解。因此，人们很难对单决策协议为什么可行建立一个直观认识。Multi-Paxos的规则由增加了很大的额外的复杂性和隐晦性。我们认为达到多决策共识（例如，一个日志而不是单个日志条目）的整个问题可被分解为更直观更显然的其他方式。

Paxos的第二个问题是它没有为构建实用的实现提供良好的基础。其原因之一是人们对multi-Paxos算法没有广泛的一致意见。Lamport的描述几乎都关于单决策Paxos；他概括了multi-Paxos的可能的方法，但缺少许多细节。后来出现了很多试图具体化并优化Paxos的尝试，如<sup>[26, 39, 13]</sup>，但这些方法互相之间都不一样且与Lamport的蓝图也不通。像Chubby<sup>[4]</sup>这样的系统实现了类Paxos算法，但在大多数条件下的细节都没有发表。

此外，Paxos架构对构建实用系统来说很弱；这时将算法分解为单决策的另一个后果。例如，单独选取一组日志中的每个条目并将它们合并为一个顺序日志并没有什么还出；这样做只会增加复杂性。设计一个围绕系统的日志更加简单且高效，其中新日志条目可以按照受约束的顺序被依次添加。另一个问题是，Paxos的核心使用了一个对称的（symmetric）对等(peer-to-peer)方法（尽管其最后提出了一个弱领导权方法作为性能优化）。这在仅需要做一个决策的简单的世界中是有意义的，但是对于使用这种方法的实用系统来说意义不大。如果必须做出一系列决策，那么先选举出一个leader更简单却更快，随后让该leader协调决策。

因此，使用系统与Paxos相似之处很少。每个实用系统的实现首先都会从Paxos开始，然后发现很难实现它，接着开发了一个非常复杂的架构。这很消耗时间且容易出错，且Paxos难以理解加剧了这一问题。Paxos的表达形式可能对于证明其理论正确性来说很好，但是因为其真实实现与Paxos太过不同，这样理论证明就失去了价值。来自Chubby的实现者的评论尤为典型：

{{< admonition quote >}}
现实系统的需求的与Paxos算法的描述之间有很大的隔阂。为了构建现实的系统，专家需要使用分散在各种文献中的许多思想，并作出一些较小的协议扩展。这些不断累积的扩展会非常多，最后系统会基于一个未被证明的协议。<sup>[4]</sup>
{{< /admonition >}}

因为这些问题，我们总结出Paxos没有为系统构建和教学提供良好的基础。考虑到共识对大型软件系统的重要性，我们决定尝试我们能否构建出一个能替代Paxos的且比Paxos的属性更好的共识算法。Raft就是这一实验的成果。

## 4. 为可理解性做出的设计

我们在设计Raft时有许多目标：它必须为系统构建提供完整且实用的基础，这样就能大量减少开发者所需的设计工作；它必须在所有条件下都安全，在典型的操作条件下可用；它必须能在通用操作中保持高效。但我们最重要的目标是可理解性，这也是最难的挑战。它必须能被大量读者容易地理解。另外，它必须能够建立对算法的直观直觉，这样系统构建者可以对其进行扩展，这在真实实现中是不可避免的。

在我们设计Raft时，有很多要点不得不选择替代方法。在这些场景中，我们基于可理解性对这些替代方法进行了评估：解释每个替代方法有多难？（例如：其状态空间多复杂？其有没有难以捉摸的实现？）读者完整理解该方法并实现它有多简单？

我们意识到这样的分析有很大的主观性；尽管如此，我们还是使用了两种能使其更容易被大家接受的方法。第一个方法是众做周知的问题分解方法：我们尽可能地将问题划分为能被解决、解释并理解的相对独立的子问题。例如，在Raft中，我们将其分为领导选举、日志复制、安全性和成员变更。

我们的第二个方法是通过减少需要考虑的状态数来简化状态空间，使系统鞥具有连贯性并尽可能消除不确定性。特别是，日志不允许有“洞”（译注：这里的“洞”指日志间的空隙，见Ceph的论文。），且Raft限制了日志变得与其它不一致的方式。尽管在大多数情况下，我们试图消除不确定性，但是有些情况下不确定性实际上可以提高可理解性。在实践中，随机化的方法引入了不确定性，但是它们通常会通过用相同的方法解决所有可能的选择，因此减少了状态空间。我们使用的随机化的方法简化了Raft的领导选举算法。

## 5. Raft共识算法

Raft是一种用来管理[第二章](#2-)中描述的形式的多副本日志的算法。**图2**以浓缩的形式总结了算法以供参考，**图3**列出可算法的关键性质；这些图中元素将在本章剩下的部分分条讨论。

![图2 对Raft共识算法的浓缩总结（不包括成员变更和日志压缩）。服务器的行为在左上角的的格子中被作为一系列独立且可重复的触发器规则描述。像“§5.2”这样的章节号表示某个特征将在哪一节中讨论。正式定义<sup>[31]</sup>将会更精确地描述算法。](figure-2.jpg "图2 对Raft共识算法的浓缩总结（不包括成员变更和日志压缩）。服务器的行为在左上角的的格子中被作为一系列独立且可重复的触发器规则描述。像“§5.2”这样的章节号表示某个特征将在哪一节中讨论。正式定义<sup>[31]</sup>将会更精确地描述算法。")

![图3 Raft在所有时刻都保证这些性质的每一条都成立。章节号表示每条性质将在哪一节中讨论。](figure-3.png "图3 Raft在所有时刻都保证这些性质的每一条都成立。章节号表示每条性质将在哪一节中讨论。")

Raft通过先选举一个高级leader然后给予该leader管理分布式日志的所有责任的方式实现共识。该leader接收来自客户端的日志条目，将它们复制到其它服务器上，然后告诉服务器什么时候可以安全地将这些日志条目应用到它们的状态机中。使用leader可以简化对分布式日志的管理。例如，leader可以在不询问其它服务器的情况下决定将日志的新条目放在哪儿，且数据流仅简单地从leader流向其它服务器。leader可能发生故障也可能在其它服务器中失去对其的连接，在这种情况下，会有新的leader被选举出来。

考虑leader的方法，Raft将共识问题分解成三个相对独立的子问题，接下来的小节会对这些问题进行讨论：

- **领导选举：** 当已有的leader故障时必须有新的leader被选举出来（[章节5.2](#52-)）。

- **日志复制：** leader必须接收来自客户端的日志条目，并将它们复制到集群中，强制其它日志对它自己的日志达成一致（[章节5.3](#53-)）。

- **安全性：** Raft中关键的安全性是**图3**中的状态机安全性（State Machine Safety Property）：如果任意服务器将一个特定的日志条目应用到了其状态机中，那么不会有应用了有相同index（索引）的其他指令的日志条目的服务器。[章节5.4](#54-)描述了Raft如何确保这一性质；其解决方案包括对[章节5.2](#52-)中描述的选举机制的一个额外的约束。

在给出共识算法后，本章讨论了可用性问题和定时在本系统中的角色。

### 5.1 Raft基础

一个Raft集群包括多个服务器；通常数量是5，这可以让系统能够容忍2个服务器故障。在给定时间内，每个服务器处于以下三个状态之一：leader、follower、或candidate。在正常的操作中，会有恰好一个leader，所有其它服务器都是follower。follower是被动的：它们不会自己提出请求，而仅响应来自leader和candidate的请求。leader处理所有的客户端请求（如果客户端联系了一个follower，该follower会将其重定向到leader）。第三个状态candidate，在[章节5.2](#52-)中描述的选举新leader时使用。**图4**展示了状态和状态间的转移；状态转移将在后文中讨论。

![图4 服务器状态。follower仅响应来自其它服务器的请求。如果follower没有收到通信，那么它会变为candidate并开始一次选举。收到了来自整个集群中大多数节点投票的candidate会成为新的leader。leader通常会持续到其故障。](figure-4.png "图4 服务器状态。follower仅响应来自其它服务器的请求。如果follower没有收到通信，那么它会变为candidate并开始一次选举。收到了来自整个集群中大多数节点投票的candidate会成为新的leader。leader通常会持续到其故障。")

Raft将时间划分为任意长度的term，如**图5**所示。term被编号为连续的整数。每个term从选举（election）开始，在选举中一个或多个candidate会试图成为leader，就像[章节5.2](#52-)中描述的那样。如果candidate赢得选举，那么它将在该term余下的时间了作为leader提供服务。在某些情况下，一次选举可能导致投票决裂，此时该term最终可能没有leader，那么很快会开始一个新的term（伴随一次新的选举）。Raft确保一个给定的term中最多只会有一个leader。

![图5 时间被划分为term，每个term从选举开始。在一次成功选举后，单个leader会管理集群，直到该term结束。有些选举会失败，在这种情况下，term会不选择leader就结束。term之间的转换可以在不同服务器上的不同时间被观测到。](figure-5.png "图5 时间被划分为term，每个term从选举开始。在一次成功选举后，单个leader会管理集群，直到该term结束。有些选举会失败，在这种情况下，term会不选择leader就结束。term之间的转换可以在不同服务器上的不同时间被观测到。")

不同的服务器可能在不同时间观测到term的装换，且在一些情况下，服务器可能没有观测到选举甚至没观测到整个term。term在Raft扮演逻辑时钟<sup>[14]</sup>的角色，且term能让服务器检测到过时的（obsolete）信息，如陈旧的（stale）leader。每个服务器会存储当前的term号，其随时间单调递增。当前的term号在任何服务器通信时都会被交换，日过服务器当前的term小于其它服务器的，那么它会更新其term号到到较大值。如果candidate或leader发现它的term过期了，它会立刻转到follower状态。如果服务器收到了有陈旧的term号的请求，它会拒绝该请求。

Raft服务器使用远程过程调用（remote procedure call，RPC）通信，且基本的共识算法仅需要两种RPC。RequestVote RPC在选举时由candidate发起（[章节5.2](#52-)），而AppendEntries RPC被leader发起，用来复制日志条目和提供心跳（[章节5.3](#53-)）。[第七章](#7-)加入了第三个RPC，用来在服务器间传输快照。如果服务器没有及时收到响应，它们会重试RPC，且它们会并行地发起RPC以获得最佳性能。

## 5.2 领导选举

Raft使用心跳机制来触发领导选举。当服务器启动时，它们按照如下方式开始。只要服务器能收到来自leader或candidate的合法的RPC，它就会保持follower状态。leader会定期发送心跳（不携带任何日志条目的AppendEntries RPC）给所有follower，以维护其权威。如果follower在超过一段时间后（这段时间被称为选举超时时间，election timeout）仍没受到通信，那么它会假设当前没有可行的leader，并开始一次选举以选择一个新leader。

为了开始一次选举，follower会增大其当前的term，并转换到candidate状态。其随后为自己投票，并并行地给集群中每个其它的服务器发起RequestVote RPC。candidate会保持其状态，知道以下三件事情之一发生：（a）它赢得了选举；（b）另一个服务器成为了leader；（c）一段时就过后仍没有胜者。这些后果将在后文中分别讨论。

如果candidate收到了整个集群中大多数相同term服务器的投票，那么它会赢得选举。在一个给定的term中，每个服务器会按先到先得（first-come-first-served）的方式给最多一个candidate投票（注意：[章节5.4](#54-)对投票增加了一个额外约束）。“大多数”规则确保了在特定的term中最多只有一个candidate能赢得选举（选举安全性如**图3**所示）。一旦candidate赢得选举，它会变成leader。随后它会向所有其他服务器发送心跳消息以建立起权威，并防止新选举发生。

在等待投票时，candidate可能收到来自其它服务器声明自己是leader的AppendEntries RPC。如果leader的term（包括在其RPC中）至少与该candidate当前的term一样大，那么这个candidate会视其为合法的leader，并返回到follower状态。如果RPC中的term比该candidate当前的term小，那么该candidate会拒绝RPC并继续以candidate状态运行。

第三种可能的结果是，candidate既没有赢得选举也没有输：如果许多follower在同时变成了candidate，投票可能决裂，这样可能没有candidate获取大多数的投票。当这种情况发生时，每个candidate都将会超时并通过增大其term和开始另一轮RequestVote RPC来开始新的一轮选举。然而，如果不采取额外措施，投票决裂可能会无限反复。

Raft使用了随机额选举超时时间以确保投票决裂很少发生，且投票决裂可以被快速解决。为了在初次选举时防止投票决裂，选举超时时间会从一个固定的时间段（例如，150~300ms）中随机选取。这会在所有服务器上实现，这样大多数情况下只有单个服务器会超时，它会在任何其它服务器超时前赢得选举并发送心跳。同样的机制还在处理投票决裂时使用（译注：之前介绍的是**防止**投票决裂，接下来是**处理**投票分裂）。每个candidate在开始选举时重置其随机选举超时时间的计时器，且它会在下一次选举开始前等待该超时时间流逝，这减少了新的选举中再次发生投票决裂的可能性。[章节9.3](#93-)说明这种方法能快速地选出leader。

选举是可理解性如何指导我们在备选设计中做出选择的一个实例。最初我们计划使用一个排名（ranking）系统：假设每个candidate有一个唯一的排名（rank），这个排名会在选取竞争中的candidate时使用。如果candidate发现了有更高排名的另一个candidate，它会返回follower状态，这样有更高排名的candidate能够更容易地赢得下一次选举。我们发现这种方法制造了有关可用性的隐晦的问题（如果排名较高的服务器故障，排名较低的服务器可能需要等待超时才能再次成为candidate，但是如果它再次成为candidate过早，它可能会重置领导选举的进度）。我们对该算法做了很多次调整，但是在每次调整后都会出现新的小问题。最终我们总结出，随机重试的方法更显而易见且易于理解。

### 5.3 日志复制

一旦leader被选举出来，它会开始为客户端的请求提供服务。每个客户端请求包含一条需要被多副本状态机执行的指令。leader将该指令作为新的条目追加到其日志中，随后它会并行地向每台其他的服务器发起AppendEntries RPC复制该条目。当该条目被安全地复制时（正如后文描述的那样），leader会将该条目应用到其状态机中，并将执行的结果返回给客户端。如果follower崩溃或运行缓慢，或者如果网络包丢失，leader会无限重试AppendEntries RPC（即使它已经响应了客户端），知道所有的follower最终存储了所有的日志条目。

![图6 日志由条目组成，日志条目被顺序编号。每个日志条目都包含它被创建时的term号（每个方框中的数字）和一条给状态机的指令。如果一个日志条目能被安全地应用到状态机中，它会被视为committed。](figure-6.png "图6 日志由条目组成，日志条目被顺序编号。每个日志条目都包含它被创建时的term号（每个方框中的数字）和一条给状态机的指令。如果一个日志条目能被安全地应用到状态机中，它会被视为committed。")

日志被按照如**图6**的方式组织。每条日志都保存了一条状态机指令和leader收到该条目时的term号。日志条目中的term号被用作检测日志间的不一致性并确保**图3**中的一些性质。每个日志条目还有一个标识它在日志中的位置的整数index（索引）。

leader会决定什么时候能够安全地将日志条目应用到状态机，这种条目被称为committed（已提交）的。Raft保证committed的条目时持久性的，且最终将会被所有可用的状态机执行。一旦撞见了日志条目的leader将其如知道了大多数服务器上，那么该条目会变成committed的（例如，**图6**中的条目7）。这还会提交在leader的日志中所有之前的条目。[章节5.4](#54-)讨论了在leader变更后应用这一规则的一些微妙的情况，其还展示了“提交是安全的”的定义。leader会跟踪它知道的被提交的最高的index，且它会在之后的AppendEntries RPC中包含这个index，这样其它server最终会发现它。一旦follower得知一个日志条目被提交，它会将该条目（按日志顺序）应用到它本地的状态机中。

我们设计的Raft日志机制能维护不同服务器间高级别的连贯性。这不但简化了系统的行为，还使系统更可预测，这时确保安全性的重要部分。Raft维护的如下的性质共同构成了**图3**中的“日志匹配性质（Log Matching Property）”：

- 如果不同日志的两个条目有相同的index和term，那么它们存储了相同的指令。

- 如果不同日志的两个条目有相同的index和term，那么日志中之前的所有条目都是相同的。

